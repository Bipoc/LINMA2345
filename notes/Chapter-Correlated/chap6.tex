\ifx \globalmark \undefined %% This is default.
	\input{../header}
	\begin{document} %% Crashes if put after (one of the many mysteries of LaTeX?).	
\else 	
\fi


\chapter{Games with communication}
{\large{\itshape
``Two monologues do not make a dialogue''} --- Jeff Daly.\\
}
\label{chap:Cor}
  {\small{\itshape
Chapter based on pages 244 to 263 of the book  ``Game theory - Analysis of conflict'' by R. Myerson.}\\
}


So far, we have considered situations where the different players of a game made their decision independently of one another. After analysis of the game, each player decides on his (sequence of) rational moves.\\
Suppose now that the players were allowed to communicate before and during the game. Then whole new possibilities may arise. It seems clear that they should be able to improve their payoffs. In this chapter, we explore how communication can be exploited in some typical situations.

\section{Correlated strategies and mediators}

We consider that players now  make use of some communication mechanisms to agree on the outcome of a game. It is important to distinguish between the actions (strategies) and outcomes (what will actually happen). This is illustrated in the following example: 

\begin{example}[Crossroads (a.k.a. ``chicken'')]
Two drivers are arriving at high speed at a crossroad (Figure \ref{ch6:fig:crossroads}).
\begin{figure}[!ht]
\centering
\includegraphics[scale=1.5]{crossroads.eps}
\caption{Who goes first?}
\label{ch6:fig:crossroads}
\end{figure}
The drivers can either wait (w) and stop at the crossroad, or go on (g). 
We will represent this as a 2 player game, with the following strategic form 
\begin{center}
\begin{tabular}{c | c  c}
& g & w\\
\hline
G & -10, -10 & 2, 0  \\
W & 0, 2 & -1, -1 
\end{tabular}
.
\end{center}

There are four outcomes for this game: players can have an accident (which matches the choice of strategies ([G],[g])), or player 1 waits ([W],[g]), or player 2 waits ([G],[w]), or both wait ([W],[w]). \\
The game has 3 Nash Equlibria: $([G],[w])$, $([W],[g])$, and $(\frac{3}{13}[G] + \frac{10}{13}[W], \frac{3}{13}[g] + \frac{10}{13}[w])$. We know that, since the players are rational, they are \emph{going to play at a Nash equilibrium}. \\
What does this mean? It means that for this games, player 1 may pick [G], [W] or 0.5[G] + 0.5[W] depending on what he \emph{believes} player 2 is going to do. The same occurs for player 2. 
However, it may very well be the case that player 1 thinks player 2 is going to stop, and the reverse holds for player 2. As a consequence, the players may crash rationally even if neither one played the randomized equilibrium.

Of course, in practice, we know several ways to solve the crossroad problem. In Belgium, the \emph{law} states that we should always let the one arriving from the right go first. If we break the law, we face dire consequences (first, we may have an accident, and second, if we get caught, we can be heavily reprimanded).

Another way to solve this problem is by installing a \emph{traffic light} at the crossroad. At every instant, the red light actually suggests to the players an outcome for the game ([G],[w]) or ([W],[g]). Most of the time, players follow this recommendation since if we receive a signal not to go, we know the other one is signalled to go. Thus, if we do not follow recommendations, we actually chose to have an accident.

Yet another way to solve this problem would be through communication. We could imagine a situation where the players are able to send signals to each others, and decide (perhaps by tossing a coin) on a suitable outcome for the game. A reasonable strategy for the players would be to pick the outcome ([G],[w]) or ([W],[g]), each with probability $1/2$.

\label{ch5:example:crossroads1}
\end{example}

We will be considering games in strategic form $\Gamma(N,C,u)$. The set of possible \emph{outcomes} of the game is simply $\times_{i \in N} C_i$, and the players will try to agree on an outcome in this set, or (as in the example above) on a randomization in $\Delta (\times_{i \in N} C_i)$. We call elements of this last set \emph{correlated strategies}.

\begin{definition}
For a game in strategic form $\Gamma(N,(C_i)_{i \in N}, (u_i)_{i \in N})$, a correlated strategy is a point $\mu \in \Delta (\times_{i \in N} C_i)$. \\
The payoff of player $i \in N$ for a correlated strategy $\mu$ is given by 
$$U_i(\mu) = \sum_{c \in C} \mu(c) \cdot u_i(c).$$
\end{definition}

Before moving further, let us give more explanations about \emph{why} do we call these $\mu$ \emph{correlated strategies}? 
Any given a randomized strategy profile $\sigma \in \times_{i \in N} \Delta(C_i)$ corresponds to a unique correlated strategy $\mu$, where 
$$\forall c = (c_i)_{i \in N} \in C, \mu(c) = \prod_{i \in N} \sigma_i(c_i). $$
However, the reverse does not hold: when choosing their strategies \emph{independently} of one another,  there are some correlated strategy that cannot be reached by the players (this is shown in the next example). Thus the name: in correlated equilibria, the probability distribution of the actions of the different players are allowed to be correlated with each other, which enables much more possibilities than in classical standard games.

\begin{example}
Assume, in the crossroads example, that the player want to implement the \emph{correlated strategy} $0.5([G], [w]) + 0.5 ([W], [g])$. To do so, player 1 can for example toss a coin, and communicate the result to player 2 (assuming player 1 is truthful).  Alternatively, they can make use of a red-light (if present).\\
Something they can not do, however, is to play according to a randomized strategy - say $\alpha_1[G] + (1-\alpha_1)[W]$ for the first player, and $\alpha_2[g] + (1-\alpha_2)[w]$ for the second.
Indeed, this requires
$$ \mu([G], [g]) = \alpha_1 \alpha_2 = 0; \mu([G], [w]) = \alpha_1 (1-\alpha_2) = 0.5, \mu([W], [g]) = (1-\alpha_1) (\alpha_2) = 0.5, $$
which is impossible.
\end{example}

We can already conclude that considering correlated strategies opens new horizons to the players, because this allows for outcomes that are impossible to reach when players chose their moves independently of each other.\\
Now, for the question of  ``how will they implement the strategy'', we will rely on a tool called a \emph{mediator} - which can be seen as a (neutral) third-party, whose role is to guide the players in their choices. The red-light in the crossroad example is a perfect example of a mediator. 

The role of a mediator is to    
\begin{enumerate}
\item Describe a correlated strategy to the player, 
\item privately sample and outcome following the correlated strategy,
\item secretly tell, to each of the players, what they should play to reach this outcome.
\end{enumerate}

It is true, however, that we don't always have access to a third party mediator. Sometimes we can only communicate between players (in a more or less restrictive way). The good news is: this is not a problem, as explained next.

\subsection{Communication, Mediators and the Revelation Principle}

To be able to exploit communication to improve payoffs, one first needs to define what ``communication'' means. A very broad (and rich) definition suggests that players can talk, send messages to each other, lie about their plans or their private information, etc. Thus, in a game with communication, a player must chose what to say to whom, interpret the message he receives, and take his decisions.

Point being: if we wish to study games with communications, we may just build a huge game where at every step, every different communication option is seen as a move. Of course, with such a broad definition, studying how communications may affect the outcome of the game appears to be quite a challenge. However, it turns out that any such communication situation can be modelled with the help of  a \emph{mediator} (a neutral player who chooses a \emph{correlated strategy} for the players). This fact is known as the \emph{revelation principle}.




\section{Correlated equilibria}

We now investigate the notion of \emph{correlated equilibria}. 
Basically, when a mediator enters the game, he proposes a correlated strategy. We now play a new game, where each player now has a additional move he can play: he can decide to follow the recommendation of the mediator. The correlated strategy will be a \emph{correlated equilibrium} if the situation where all players accept to follow the recommendation is a \emph{Nash equilibrium} of this new game.

We consider two cases. In the first case, the mediator present the player with a \emph{binding contract} that the players must decide to sign or not. In the second case, a correlated strategy is suggested. The mediator then secretly tells to each player which move to do in order to implement the strategy, but the players will keep the possibility of choosing the actual action they implement in the end. Our goal is then to propose strategies such that no player would cheat the mediator.

\subsection{Binding contracts}
\label{ch5:sec:cont}
We first assume that the players have two options. Either they can sign a contract with the mediator, and they will receive his recommendation, but they have to follow it (binding contract with the mediator). Or, they don't sign the contract, and will be able to play the move of their choice, knowing that perhaps other players will sign.  
The contract can have a very broad form, and the recommendation of the mediator might vary according to which players did sign the contract. In general, we define a contract as follows:

\begin{definition}
Given a game $\Gamma(N,C,y)$, a contract $\tau$ is a function
$$ \tau : S \subseteq N \rightarrow \Delta \times_{i \in S}(C_i), $$
that assigns to each subset of players $S$ the correlated strategy  they will play if they sign all together.
\end{definition} 

Notice that in the definition above, $\tau(N)$ is actually a correlated strategy as defined in the previous section. For any other $S \subset N$, $\tau(S)$ is also a correlated strategy, but which is going to be implemented only by the members of the set $S$ that sign the contract. 
The players who do not sign the contract are free to choose an action in their action set.

As mentioned above, our goal is to understand when the situations where all players sign the contract are  Nash equilibria. 

\begin{proposition}
Consider a game $\Gamma(N,C,u)$, and a contract $\tau$ for this game. The correlated strategy $\tau(N)$ is a correlated equilibrium if and only if 
$$ \max_{c_i \in C_i} \sum_{c_{-i} \in C_{-i}} \tau(N \backslash i, c_{-i})u_i(c_i, c_{-i}) \leq \sum_{c \in C} \tau(N; c) u_{i}(c),$$
where for $S \subseteq N$, $c \in \times_{i \in S} C_S$, $\tau(S,c)$ is the probability that the players in $S$ having signed the contract play the strategy $c$.
\end{proposition}

In other words, assuming that the other players will sign the contract, you won't if you can obtain a higher payoff by playing on your own. \\
Assume now that, as a mediator, you wish to propose a contract where $\tau(N)$ is a correlated equilibrium. A player won't sign the contract unless he has some incentive to do so. One way to do so is by using a threat, by choosing  a $\tau(N \backslash i)$ that would guarantee that $i$ would prefer to sign. In order to do this, we may use its \emph{minimax value}.

\begin{definition}
The \emph{minimax value} for player $i$ is defined as
\begin{align*}
v_i = \min_{\tau_{-i} \in \Delta(C_{-i})} \max_{c_i \in C_i} \sum_{c_{-i} \in C_{-i}} \tau_{-i}(c_{-i}) \cdot u_i(c_{-i}, c_i).
\end{align*}
\end{definition}


Certainly, a player should never sign a contract in which he does not receive at least his minimax value (because he can ensure this amount on his own). But he  should sign the contract if the reward he would get is at least his minimax value? The answer is given by the following theorem.

\begin{theorem}
Consider a correlated strategy $\mu$. There exists a contract in which all players signing is an equilibrium if and only if $U_i(\mu) \geq v_i$ for all $i \in N$.
\end{theorem}

\noindent To see why this is true, consider a contract specifying the following rules:
\begin{itemize}
	\renewcommand{\labelitemi}{$\bullet$}
	\item if all players sign, then they should play $\mu$ (that is $\tau_N = \mu$);
	\item if all players but $i$ sign, then the players in $N-i$ should play the minimax value of player $i$.
\end{itemize}
In such a situation, it is never in the interest of $i$ to deviate (= not sign) alone from the equilibrium where everybody signs, unless he gets a better payoff with his minimax value than with the contract.



\subsection{Correlated equilibria for games in strategic form}
\label{ch5:sec:cor}


	
Let us assume now that the players do not have to sign any contract, so they are free to follow the plan of the mediator or to deviate from it during the game. To ensure that the latter case does not occur, a correlated equilibrium for such a game in \emph{strategic form} must satisfy the following strategic incentive constraints:
\begin{definition}
A correlated strategy $\mu$ satisfies to the \emph{strategic incentive constraints} if
\begin{align*}
	U_i(\mu) \geq \sum_{c \in C} \mu(c) \, u_i(c_{-i}, \; \delta(c_i)), \quad \forall i \in N, \ \forall \delta : C_i \rightarrow C_i,
\end{align*}
where $c = (c_{-i}, c_i)$, $c_{-i}$ being the strategy of the players other than $i$, and where $\delta(c_i)$ is a cheating function that replaces any strategy $c_i \in C_i$ suggested by the mediator by a strategy $\delta(c_i)$. \\
A correlated strategy satisfying the strategic incentive constraints is said to be \emph{incentive compatible.}
\label{ch6:def:incentive}
\end{definition}


These constraints require that the players cannot improve their payoff by deviating from the correlated strategy $\mu$ suggested by the mediator. Note that cheating would be perfectly rational if it was the case.
Indeed, when a mediator dictates to a player what he should do to follow the correlated strategy, the player may infer a probability distribution on the other players moves. 
More precisely, if a mediator implementing $\mu$ tells $i$ to play $c_i$, then the other players are going to play according to
$$ \sigma_{-i}(c_{-i}) = \frac{\mu(c_{i}, c_{-i})}{ \sum_{e_{-i} \in C_{-i}} \mu_(c_i, e_{-i})}.$$
Given this knowledge, a rational player would naturally compute his best response to $\sigma_{-i}(c_{-i})$ and, if this brings him a better payoff than the one obtained by following the recommendation, he will adopt the best response.

\begin{example}
For the crossroads example, the correlated strategy $\mu = 0.5([G], [w]) + 0.5 ([W],[g])$ is incentive compatible. 
Indeed, if a player is told to slow down, this player can infer that the other player has been told to keep going. Thus, if the first player decided to cheat and kept moving, an accident would surely happen.\\
On the other hand, the correlated strategy $\mu = ([W],[w])$ cannot be incentive compatible. Indeed, since the other player is being told to slow down, the best response is just to keep moving.
\end{example}

 Note that, because of the cheating function, the  formulation of Definition \ref{ch6:def:incentive} describes a polytope with an exponential number of inequalities. To avoid this problem, we can equivalently rewrite the conditions with a polynomial number of inequalities as follows:
\begin{align*}
	\sum_{c_{-i} \in C_{-i}} \mu(c) \, \big( u_i(c_{-i}, \; c_i) - u_i(c_{-i}, \; e_i) \big) \geq 0, \quad \forall i \in N, \ \forall c_i \in C_i, \ \forall e_i \in C_i.
\end{align*}

Finally, note that we may have several possible incentive compatible correlated strategies. The mediator still needs to pick one. 
One way to do this is by maximizing some objective function. For example, 
one may try to maximize $U_1(\mu) + U_2(\mu)$ (total amount of utility). The good news is that such objective functions are \emph{linear} in the variables $\mu(c)$, $c \in C$, and thus for instance, \emph{the problem of finding an incentive compatible mechanism that maximizes total payoff is a linear program}. 

\section{Correlated equilibria for Bayesian games}
\label{ch5:sec:bay}

People are able to cheat when it is in their interest, but what about lying?

We now consider \emph{Bayesian games with communication}. Recall that a Bayesian game is defined as $\Gamma(N,C,T,p,u)$, where the $T = (T_i)_{i \in N}$ are the \emph{types} of each players, 
$p = (p_{i})_{i \in N}$ where $p_i : T_i \rightarrow \Delta(T_{-i})$ and the payoffs are defined as $u = (u_i)_{i \in N}$ with
$$u _i : T \times C \rightarrow \reels. $$
That is, the payoffs of the players now depend on their types! 
This complicates the task of a mediator. He must propose an incentive compatible correlated strategy for every possible combination of types, which can be written as a conditional probability function of the form
$$ \mu : T \rightarrow \Delta(C).$$ 
The task of a mediator can now be described as 
\begin{enumerate}
\item Propose to the players a set of correlated strategies $\mu(\cdot | t)$, one per combination of types $t \in T$. 
\item Collect the types of the players.
\item Privately compute the outcome of the correlated strategy.
\item Secretly communicate his recommendations to each players.
\end{enumerate}

For a correlated strategy $\mu$, the payoff of player $i$ given his type $t_i$, is given by:
\begin{align*}
	U_i(\mu \; | \; t_i) = \sum_{t_{-i} \in T_{-i}} \sum_{c \in C} p_i(t_{-i} \; | \; t_i) \, \mu(c \; | \; t) \, u_i(c, \; t),
\end{align*}
where $t = (t_{-i}, t_i)$ and $T_{-i}$ are the set of possible combinations of types for the  players other than $i$.\\


The problem is that,  to guarantee a desired outcome, the mediator needs not only propose an incentive compatible strategy for each combination  of types, be he must also be sure that he knows the correct types for the players for doing the recommendations.

\begin{example}
Back at our crossroads!
Consider the following situation. You are an engineer working on a \emph{``smart crossroad''} project. 
The idea is the following: some drivers (type V for VIP) are more important than others (type R for Regular). For example, those driving an ambulance should have priority on those who are just doing their groceries.\\
The cars of your city have been equipped with rudimentary devices, that broadcast whether they are VIP drivers or not. We would like to allow the VIP to pass whenever they are in the presence of regular drivers. \\
Assume the following bayesian model for the game:
\begin{center}
\begin{tabular}{c | c  c}
R vs R & g & w\\
\hline
G & -10 / -10 & 2 / 0  \\
W & 0 / 2 & -1 / -1 
\end{tabular}
\begin{tabular}{c | c  c}
R vs V & g & w\\
\hline 
G & -30 / -10 & 2 / -1  \\
W & 1 / 5 & -1 / -5 
\end{tabular}
\begin{tabular}{c | c  c}
V vs R & g & w\\
\hline 
G & -10 / -30 & 5 / 1  \\
W & -1 / 2 & -5 / -1 
\end{tabular}
\begin{tabular}{c | c  c}
V vs V & g & w\\
\hline 
G & -10 / -10 & 2 / 0  \\
W & 0 / 2 & -1 / -1 
\end{tabular}
\end{center}
Regarding the beliefs functions $p$, we may assume $p(V | R) = p(V | V) =  p(V) = 0.1$, $p(R | R) = p(R | V) = p(R) = 0.9$ as objective probabilities.

The problem is that most resident of the city are talented engineers, and they can hack the broadcast device with ease.
Could you build a policy, using red-lights, that allows VIP drivers to have priority over regular ones, but that would also discourage all drivers to hack their devices?



A naive approach would be to consider each of the four cases separately, and prepare one incentive compatible mechanism for each which, for example, would maximize total payoff.
In our case, this yields
\begin{itemize}
\item $\mu(\cdot | RR) = 0.5([G], [w]) + 0.5([W], [g])$,
\item $\mu(\cdot | RV) = ([W], [g])$,
\item $\mu(\cdot | VR) = ([G], [w])$,
\item $\mu(\cdot | VV) = 0.5([G], [w]) + 0.5([W], [g])$,
\end{itemize}

Assume now that, as a regular driver, you were aware that the above was the strategy implemented at the crossroads. Would you hack your broadcast device to appear as a VIP?

Assume you broadcast as a regular driver. Your payoff is then going to be 
$$ U_1(\mu | R) =  p(R) u_1(\mu(\cdot | RR) | RR) + p(V)  u_1(\mu(\cdot | RV) | RV) = 0.9 \cdot 1 + 0.1 \cdot 1 = 1. $$
Indeed, with probability $p(R)$, the other player is of type $R$, so the recommendations are then given by $\mu(\cdot | RR)$. With probability $p(V)$, the other player is of type $V$, so we receive recommendations according to $\mu(\cdot | RV)$.
If, instead we decided to broadcast your type as VIP, your payoff would become
$$ p(R) u_1(\mu(\cdot | VR) | RR) + p(V)  u_1(\mu(\cdot | VV) | RV) = 0.9 \cdot 2 + 0.1 \cdot 1.5 = 2.85. $$
It is important to understand that we would receive the payoffs of a regular player, but the recommendations of a VIP driver. Thus, we get priority over regular drivers, and equal chances to go or wait versus a VIP driver.


In conclusion, yes, it would be rational to hack the device. The design of the proposed strategy did not take this into account.
\end{example}


\begin{definition}
A bayesian correlated strategy $\mu : T \rightarrow \Delta C$ is incentive compatible if it satisfies to the constraints
\begin{align*}
	U_i(\mu \; | \; t_i) \geq U_i^*(\mu, \; \delta_i, \; s_i \; | \; t_i), \quad \forall i \in N, \ \forall t_i \in T_i, \ \forall s_i \in T_i, \ \forall \delta_i : C_i \rightarrow C_i,
\end{align*}
with 
\begin{align*}
	U_i^*(\mu, \; \delta_i, \; s_i \; | \; t_i) = \sum_{t_{-i} \in T_{-i}} \sum_{c \in C} p_i(t_{-i} \; | \; t_i) \, \mu(c \; | \; t_{-i}, s_i) \, u_i\big( \; (c_{-i}, \; \delta_i(c_i)) \;, \; t \big),
\end{align*}
where $t_i$ is the type of $i$, $s_i$ is the type that $i$ reveals to the mediator and $\delta_i$ is the function chosen by player $i$ that, for any action $c_i$ that can be suggested by the mediator, chooses an action $\delta_i(c_i)$ to play instead. 
\end{definition}

These constraints impose that the players neither have interest to lie on their type, nor to deviate from the correlated strategy $\mu$ suggested by the mediator. 


\begin{example}


We now conclude our crossroad example by presenting a mechanism satisfying to the incentive constraints for the bayesian game.

One may verify that the following strategy is incentive compatible
\begin{itemize}
\item $\mu(\cdot | RR) = 0.5([G], [w]) + 0.5([W], [g])$,
\item $\mu(\cdot | RV) = ([W], [g])$,
\item $\mu(\cdot | VR) = ([G], [w])$,
\item $\mu(\cdot | VV) = 1/3([G],[g]) + 1/3([G], [w]) + 1/3([W], [g])$.
\end{itemize}


The approach is quite dangerous: in order to deter a regular player from lying, we tell him that VIPs tend to crash into VIPs. Since crashing into a VIP has a very high cost for a regular driver, he then has no interest into lying.

\end{example}



\subsection{Collective choice problems}
\label{ch5:subs:coll}
Before ending this section, we mention a special type of bayesian games with communications, known as \emph{Collective choices problems}.  Here we assume that the players will follow the recommendations of the mediator, as if they had signed a contract beforehand, but they can still lie about their types. The task of a mediator is the same as before.

In this case, the incentivity constraints are but a special case than the ones before:
\begin{definition}
For a collective choice problem, a bayesian correlated strategy $\mu : T \rightarrow \Delta C$ is incentive compatible if it satisfies to the constraints
\begin{align*}
	U_i(\mu \; | \; t_i) \geq U_i^*(\mu,  \; s_i \; | \; t_i), \quad \forall i \in N, \ \forall t_i \in T_i, \ \forall s_i \in T_i, 
\end{align*}
with 
\begin{align*}
	U_i^*(\mu, \;  s_i \; | \; t_i) = \sum_{t_{-i} \in T_{-i}} \sum_{c \in C} p_i(t_{-i} \; | \; t_i) \, \mu(c \; | \; t_{-i}, s_i) \, u_i\big( \; (c_{-i}, \; c_i )\;, \; t \big),
\end{align*}
where $t_i$ is the type of $i$, $s_i$ is the type that $i$ reveals to the mediator.
\end{definition}



\section{Moral hazards and adverse selection}

These ideas that players may lie about their types, or not follow recommendations, are very important in the insurance industry.\\
 The first case is referred to as \emph{moral hazard}: people will usually tell their insurer that they plan to drive very safely, even if they really like to drive fast. Fast drivers are even more tempted to do so, since the data indicate they are more prone to having accidents.\\
  The second case is referred to as \emph{adverse selection}: once covered by a good insurance, some people then prefer to drive fast (even if they were naturally cautious persons).
  
  Overall, the contents of this chapter can be split into four categories:
  
  \begin{tabular}{c | c | c}
  & With moral hazard & Without moral hazard \\
  \hline
  With adverse selection   & Section \ref{ch5:sec:bay} &  Subsection \ref{ch5:subs:coll} \\
  \hline
  Without adverse selection  & Subsection \ref{ch5:sec:cor}  & Subsection \ref{ch5:sec:cont} \\
  \end{tabular}  
 

 
  
 



\ifx \globalmark \undefined %% This is default.
\bibliographystyle{plain}
\bibliography{../gametheorybibliography}
	\end{document}
\else 
	
\fi

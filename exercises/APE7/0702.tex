\paragraph{a.} Let's first define what a belief vector is : for $\pi \in  \times_{s \in S} \Delta Y_s $, $i \in N$, $s \in S_i$, and $x \in Y_s$, $\pi_s(x)$ is the probability assigned by player $i$ to be at node $x$ given the fact that $i$ knows his information state $s$. ($X$ the nodes, $Y_s\in X$ is the set of nodes that have information $s$). 

We can calculate it with Bayes formula $$ \pi_s(y) = \frac{P(y | \tau, x^0)}{\sum_{x \in Y_s} P(x | \tau, x^0)}. $$

Here there is four nodes and three information states: 1.1, 2.2 via $a_1$ (let's note it from now on $2.2.a_1$), 2.2 via $b_1$ (again, let's note it $2.2.b_1$) and 2.3: 

\begin{itemize}
\item $\pi_{1.1}= 1$ 
\item $\pi_{2.2}(2.2.a_1) = \frac{0.6}{0.6+0.4 \cdot 0.25} = \frac{6}{7}$
\item $\pi_{2.2}(2.2.b_1)= \frac{0.4\cdot 0.25}{0.6+0.4 \cdot 0.25} = \frac{1}{7}$ 
\item $\pi_{2.3}     = 1 $
\end{itemize}
$\pi_{1.1}=\pi_{2.3} = 1$ because there is only one possible way to be at 1.1 (or 2.3) knowing that the information state is 1.1 (or 2.3).

\paragraph{b.} The sequential value of player $i$ for the move $d$ and information state $s$ $$ U_i(d| s, (\tau, \pi) ) = \sum_{x \in Y_s} \pi_s(x) U_i((\tau_{-i}, d), x)$$
Meaning that we will only care about nodes $x$ with information $s$. 

We obtain : 
\begin{itemize}
\item $U_1(a_1|1.1) = \pi_{1.1} (0.9 \cdot 2 + 0.1 \cdot 8) = 2.6$
\item $U_1(b_1|1.1) = 0.25 (0.9 \cdot 9 + 0.1 \cdot 1) + 0.75 (0.05 \cdot 9 + 0.95 \cdot 1) = 3.1$
\item $U_2(a_2|2.2) = \pi_{2.2.a_1} \cdot -1 + \pi_{2.2.b_1} \cdot 0 = \frac{-6}{7}$
\item $U_2(b_2|2.2) = \pi_{2.2.a_1} \cdot -6 + \pi_{2.2.b_1} \cdot 4 = \frac{-32}{7}$
\item $U_2(c_2|2.3) = \pi_{2.3} \cdot 0 = 0 $
\item $U_2(d_2|2.3) = \pi_{2.3} \cdot 4 = 4$
\end{itemize}

\paragraph{c.}\label{parac} The irrational actions for each state of information are :

\begin{itemize}
\item 1.1 : $a_1$ is an irrational action because $U_1(a_1|1.1) < U_1(b_1|1.1)$, so player 1 will prefer to play $b_1$.
\item 2.2 : $b_2$ is an irrational action because $U_2(b_2|2.2) < U_2(a_2|2.2)$, so player 2 will prefer to play $a_2$.
\item 2.3 : $c_2$ is an irrational action because $U_2(c_2|2.3) < U_2(d_2|2.3)$, so player 2 will prefer to play $d_2$.
\end{itemize}

\paragraph{d.} Let's create the following values and assign them to a possible move for each player:

\begin{itemize}
    \item $\alpha$ to $a_1$, $1-\alpha$ to $b_1$
    \item $\lambda$ to the state $2.2.a_1$ and $1-\lambda$ to the state $2.2.b_1$
    \item $\beta$ to $a_2$ and $1-\beta$ to $b_2$
    \item $\gamma$ to $c_2$ and $1-\gamma$ to $d_2$
\end{itemize} 
with each of them being between 0 and 1, representing the probability of playing each move ($\alpha$ represent the probability of player one to play $a_1$, and so on).

We directly see that for the information state 2.3, the player 2 will always play $d_2$ having a payoff of 4, and will never play $c_2$ as it has a payoff of 0. For it to happen, $\gamma$ must be equal to 0. $d_2$ is thus part of the equilibria at the information state 2.3. 

For the information state 2.2, we will test each support with information $s$ (a support with information $s$ is noted $D(s)$) and see if a sequential equilibrium exists for this information state. 

First we can rewrite with Bayes formula : $$\lambda = \frac{\alpha}{\alpha + \frac{1}{4} (1-\alpha)} =\frac{4\alpha}{1+3\alpha}$$ for the information state 2.2, and we also can write that 
\begin{align*}
    U_2(a_2|2.2) &= -1 \cdot \lambda + 0 \cdot (1-\lambda) = -\lambda\\
    U_2(b_2|2.2) &= -6\cdot \lambda + 4 \cdot (1-\lambda) 
\end{align*} 
\begin{itemize}
    \item $D_2=\{a_2\}$ : as player two will play $a_2$ , $\beta$ must be equal to 1 (hence $b_2$ will never be played). We need to have in this case the payoff of $a_2$ at least as preferable as the payoff of  $b_2$ to justify playing $a_2$ : $$-\lambda \geq -6\lambda + 4 (1-\lambda)$$ by replacing $\lambda$ by $\frac{4\alpha}{1+3\alpha}$, we find that $\alpha \geq \frac{1}{6}$. 
    
    Let's analyse now the payoff of the two scenarios available for player 1 at the information state 1.1: 
    \begin{align*}
        U_1(a_1|1.1) &= 1 \cdot 2 + 0 \cdot 8 = 2\\
        U_1(b_1|1.1)& = \frac{1}{4} \cdot 9 + \frac{3}{4} \cdot 1 = 3
    \end{align*}
    hence $U_1(b_1|1.1)>U_1(a_1|1.1) $. It means that the player one will always play $b_1$  and never $a_1$. We deduce that $\alpha $ must be equal to 0, which is a contradiction with $\alpha \geq \frac{1}{6}$. This move is thus not in the sequential equilibria.
    \item $D_2=\{b_2\}$: as player two will play $b_2$, $\beta$ must be equal to 0 (hence $a_2$ will never be played). Again, we need to have $b_2$ at least as preferable as $a_2$ : $$-\lambda \leq -6\lambda + 4 (1-\lambda)$$
    and we find that $\alpha \leq \frac{1}{6}$ (by using the relation of $\lambda$ and $\alpha$). 
    
   Again, let's look at the payoff of the two scenarios available for player 1 at the information state 1.1: 
   \begin{align*}
       U_1(a_1|1.1) &= 0 \cdot 2 + 1 \cdot 8 = 8\\
       U_1(b_1|1.1) &= \frac{1}{4} \cdot 1 + \frac{3}{4} \cdot 1 = 1
   \end{align*} hence $U_1(a_1|1.1)>U_1(a_1|1.1) $. It means that the player one will always play $a_1$ and never $b_1$. We deduce that $\alpha$ must be equal to 1, which is a contradiction with $\alpha \leq \frac{1}{6}$. This sequential move is thus not in the sequential equilibria.
    \item $D_2=\{a_2,b_2\}$ : we will now deal with the case where player two plays with a randomized strategy. This time we will thus have 
    $$-\lambda = -6\lambda + 4 (1-\lambda)$$ so that player two does not prefer either $a_2$ or $b_2$. We obtain $\alpha = \frac{1}{6}$ (by using the relation of $\lambda$ and $\alpha$). 
    
    We need to check now for which values of $\beta$ player one is indifferent between playing $a_1$ and $b_1$. We have 
    \begin{align*}
        U_1(a_1|1.1)&= 2\beta + 8 (1-\beta) = 8 - 6 \beta\\
        U_1(b_1|1.1)&=\frac{1}{4} (9\beta + (1-\beta) ) + \frac{3}{4} \cdot 1 = 1 + 2\beta
    \end{align*} 
    Let's equal those two expressions and we find that $\beta = \frac{7}{8}$. 
    
    We have thus found the final part of the sequential equilibria: for this equilibria, $\alpha=\frac{1}{6}$ (information state 1.1), $\beta =\frac{7}{8}$ (information state 2.2).
\end{itemize}
    
The equilibria  ($\tau$ is the behavioural strategy and $\pi$ is the belief vector) is :
\begin{align*}
        [\tau, \pi ]&= \left[ \left(\tau_{1.1},\tau_{2.2},\tau_{2.3} \right), \left(\pi_{1.1}, \pi_{2.2} , \pi_{2.3}\right) \right]\\
        &=\left[ \left(\frac{1}{6} [a_1] + \frac{5}{6} [b_1], \frac{7}{8} [a_2] +\frac{1}{8} [b_2], [d_2]\right) , \left( 1, (\frac{4}{9} [2.2.a_1];\frac{5}{9} [2.2.b_1],1\right)\right]
\end{align*} 

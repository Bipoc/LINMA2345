\paragraph{a.} Let's first define what a belief vector is : for $\pi \in  \times_{s \in S} \Delta Y_s $, $i \in N$, $s \in S_i$, and $x \in Y_s$, $\pi_s(x)$ is the probability assigned by player $i$ to be at node $x$ given the fact that $i$ knows his information state $s$. ($X$ the nodes, $Y_s\in X$ is the set of nodes that have information $s$). \\
We can calculate it we Baye's formula $$ \pi_s(y) = \frac{P(y | \tau, x^0)}{\sum_{x \in Y_s} P(x | \tau, x^0)}. $$

Here there is four information states: 1.1, 2.2 via $\text{a}_1$, 2.2 via $\text{b}_1$ and 2.3: 

\begin{itemize}
\item $\pi_{1.1}= 1$ 
\item $\pi_{2.2.a_1} = \frac{0.6}{0.6+0.4 \cdot 0.25} = \frac{6}{7}$
\item $\pi_{2.2.b_1} = \frac{0.4\cdot 0.25}{0.6+0.4 \cdot 0.25} = \frac{1}{7}$ 
\item $\pi_{2.3}     = 1 $
\end{itemize}
$\pi_{1.1}=\pi_{2.3} = 1$ because there is only one possible way to be at 1.1 (or 2.3) knowing that the information state is 1.1 (or 2.3).

\paragraph{b.} The sequential value of player $i$ for the move $d$ and information state $s$ $$ U_i(d| s, (\tau, \pi) ) = \sum_{x \in Y_s} \pi_s(x) U_i((\tau_{-i}, d), x)$$
Meaning that we will only care about nodes x with information $s$. \\
We obtain : 
\begin{itemize}
\item $U_{1.1} (\text{a}_1) = \pi_{1.1} (0.9 \cdot 1 + 0.1 \cdot 8) = 2.6$
\item $U_{1.1} (\text{b}_1) = 0.25 (0.9 \cdot 9 + 0.1 \cdot 1) + 0.75 (0.05 \cdot 9 + 0.95 \cdot 1) = 3.1$
\item $U_{2.2} (\text{a}_2) = \pi_{2.2.a_1} \cdot -1 + \pi_{2.2.b_1} \cdot 0 = \frac{-6}{7}$
\item $U_{2.2} (\text{b}_2) = \pi_{2.2.a_1} \cdot -6 + \pi_{2.2.b_1} \cdot 4 = \frac{-32}{7}$
\item $U_{2.3} (\text{c}_2) = \pi_{2.3} \cdot 0 $
\item $U_{2.3} (\text{d}_2) = \pi_{2.3} \cdot 4 = 1$
\end{itemize}

\paragraph{c.}\label{parac} The irrational actions for each state of information are :

\begin{itemize}
\item 1.1 : $\text{a}_1$ is an irrational action because $U_{1.1} (\text{a}_1) < U_{1.1} (\text{b}_1)$
\item 2.2 : $\text{b}_2$ is an irrational action because $U_{2.2} (\text{b}_2) < U_{1.1} (\text{a}_2)$
\item 2.3 : $\text{c}_2$ is an irrational action because $U_{2.3} (\text{c}_2) < U_{2.3} (\text{d}_2)$
\end{itemize}
\paragraph{d.} Let's assign those values :\begin{itemize}
    \item $\alpha$ to $a_1$, $1-\alpha$ to $b_1$
    \item $\lambda$ to the state 2.2 and $1-\lambda$ to the state 2.2
    \item $\beta$ to $a_2$ and $1-\beta$ to $b_2$
    \item $\gamma$ to $c_2$ and $1-\gamma$ to $d_2$
\end{itemize} 
We directly see that for the information state 2.3, the player 2 will always play $d_2$ and thus, for it to happen, $\gamma$ must be equal to 0. $d_2$ is thus our first sequential equilibrium. \\

For the information state 2.2, we will test each support with information $s$ ($D(s)$) and see if a sequential equilibrium exist. First we can rewrite $\lambda = \frac{\alpha}{\alpha + \frac{1}{4} (1-\alpha)} =\frac{4\alpha}{1+3\alpha}$ for the information state 2.2, and we also can write that $U_{2.2} (a_2) = -\lambda$ and $U_{2.2} (b_2) = -6\lambda + 4 (1-\lambda) $ for player 2. 
\begin{itemize}
    \item $D=\{a_2\}$ : as $a_2$ will be played, $\beta$ must be equal to 1. We need to have in this case $a_2$ at least as preferable as $b_2$ to justify playing $b_2$ : $$-\lambda \geq -6\lambda + 4 (1-\lambda)$$ by replacing lambda by $\frac{4\alpha}{1+3\alpha}$ we find that $\alpha \geq \frac{1}{6}$. \\
    We also know that the odds that player 2 plays $a_2$ are equal to 0 as it is not a rational action, since we have that $U_{1.1} (a_1) = 2 $ as $\beta = 1$, and that $U_{1.1} (b_1) = \frac{1}{4} \cdot 9 + \frac{3}{4} \cdot 1 = 3 $. So we have that $U_{1.1} (b_1)>U_{1.1} (a_1)$, meaning that playing $a_1$  will never happen and that player one will prefer playing $b_1$. Thus $\alpha $ must be equal to 0, which is a contradiction with the first condition on $\alpha$. This sequential move is thus not an equilibrium.
    \item $D=\{b_2\}$: as $b_2$ will be played, $\beta$ must be equal to 0. Again, we need to have $b_2$ at least as preferable as $a_2$ : $$-\lambda \leq -6\lambda + 4 (1-\lambda)$$
    and we find that $\alpha \leq \frac{1}{6}$. \\
    By checking the payoff of player 1 we have that $U_{1.1} (a_1) = 8$ and $U_{1.1} (b_1) = 1$, meaning that player 1 will always prefer playing $a_1$ if player 2 will play $b_2$. Thus $\alpha$ must be equal to 1, which is a contradiction with the first condition on $\alpha$. This sequential move is thus not an equilibrium.
    \item $D=\{a_2,b_2\}$ : we will not deal with the case where player two plays with a randomized strategy. This time we will thus have 
    $$-\lambda = -6\lambda + 4 (1-\lambda)$$ so that player two does not prefer either strategy. We obtain $\alpha = \frac{1}{6}$. \\
    We need to check now for which values of $\beta$ player one is indifferent between playing $a_1$ and $b_1$. We have $U_{1.1} (a_1) = 2\beta + 8 (1-\beta) = 8 - 6 \beta $ and $U_{1.1} (b_1) = \frac{1}{4} (9\beta + (1-\beta)) + \frac{3}{4} \cdot 1 = 1 + 2\beta$. Let's equal those two expressions and we find that $\beta = \frac{7}{8}$. \\
    We have thus found a new sequential equilibria: for this equilibria, $\lambda = \frac{4}{9}$ and $\alpha=\frac{1}{6}$. The equilibria is thus $(\frac{1}{6} a_1 + \frac{5}{6} b_1, \frac{7}{8} a_2 +\frac{1}{8} b_2)$.
    
\end{itemize}
